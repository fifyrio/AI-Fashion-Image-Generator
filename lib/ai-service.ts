import OpenAI from 'openai';
import { openRouterConfig, AI_MODELS } from './config';
import { ImageAnalysisResult } from './types';
import { GPT_ANALYZE_CLOTHING_PROMPT, GPT_ANALYZE_CLOTHING_NO_ACCESSORIES_PROMPT, XIAOHONGSHU_TITLE_PROMPT } from './prompts';

// AIæœåŠ¡ç±»
export class AIService {
    private client: OpenAI;

    constructor() {
        this.client = new OpenAI({
            baseURL: openRouterConfig.baseURL,
            apiKey: openRouterConfig.apiKey,
        });
    }

    // è°ƒç”¨GPTæ¨¡å‹åˆ†æå›¾ç‰‡
    async analyzeWithGPT(imageSource: string, ignoreAccessories: boolean = false): Promise<string> {
        console.log('ğŸ“¡ æ­£åœ¨è°ƒç”¨GPT API...');
        console.log('ğŸ”§ æ¨¡å‹:', AI_MODELS.GPT);
        console.log('ğŸ”§ å¿½ç•¥é…é¥°:', ignoreAccessories);

        const prompt = ignoreAccessories
            ? GPT_ANALYZE_CLOTHING_NO_ACCESSORIES_PROMPT
            : GPT_ANALYZE_CLOTHING_PROMPT;

        const content: OpenAI.Chat.ChatCompletionContentPart[] = [
            {
                type: "text",
                text: prompt
            },
            {
                type: "image_url",
                image_url: { url: imageSource }
            }
        ];

        try {
            const completion = await this.client.chat.completions.create({
                model: AI_MODELS.GPT,
                messages: [{ role: "user", content }],
                max_tokens: 4000,
                temperature: 0.7
            }, {
                headers: {
                    "HTTP-Referer": openRouterConfig.siteUrl,
                    "X-Title": openRouterConfig.siteName
                }
            });

            console.log('ğŸ“¦ APIå®Œæ•´å“åº”:', JSON.stringify(completion, null, 2));

            if (completion.choices?.[0]?.message?.content) {
                const responseContent = completion.choices[0].message.content;
                console.log('âœ… å“åº”å†…å®¹é•¿åº¦:', responseContent.length);
                console.log('ğŸ“ å“åº”å†…å®¹é¢„è§ˆ:', responseContent.substring(0, 200));
                return responseContent;
            }

            console.error('âŒ å“åº”ç»“æ„å¼‚å¸¸:', {
                hasChoices: !!completion.choices,
                choicesLength: completion.choices?.length,
                firstChoice: completion.choices?.[0],
            });
            throw new Error('GPT APIå“åº”æ ¼å¼é”™è¯¯æˆ–å†…å®¹ä¸ºç©º');
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            console.error('ğŸš¨ GPT APIè°ƒç”¨å¤±è´¥:', errorMessage);

            // æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            if (error instanceof Error && 'response' in error) {
                console.error('ğŸ” é”™è¯¯è¯¦æƒ…:', error);
            }

            throw error;
        }
    }

    // åˆ†æå›¾ç‰‡æ¥å£ - åªä½¿ç”¨GPTæ¨¡å‹
    async analyzeImage(imageSource: string, filename: string, ignoreAccessories: boolean = false): Promise<ImageAnalysisResult> {
        const startTime = new Date();

        try {
            const analysis = await this.analyzeWithGPT(imageSource, ignoreAccessories);

            return {
                filename,
                modelName: AI_MODELS.GPT,
                analysis,
                timestamp: startTime,
                success: true
            };
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            return {
                filename,
                modelName: AI_MODELS.GPT,
                analysis: '',
                timestamp: startTime,
                success: false,
                error: errorMessage
            };
        }
    }

    // ç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾æ ‡é¢˜
    async generateXiaohongshuTitle(clothingDescription: string, imageCount: number): Promise<string> {
        console.log('ğŸ“ æ­£åœ¨ç”Ÿæˆå°çº¢ä¹¦æ ‡é¢˜...');
        console.log('ğŸ”§ æ¨¡å‹:', AI_MODELS.GPT);

        const prompt = XIAOHONGSHU_TITLE_PROMPT
            .replace('{clothingDescription}', clothingDescription)
            .replace('{imageCount}', imageCount.toString());

        try {
            const completion = await this.client.chat.completions.create({
                model: AI_MODELS.GPT,
                messages: [
                    {
                        role: "user",
                        content: prompt
                    }
                ],
                max_tokens: 2000,
                temperature: 0.8
            }, {
                headers: {
                    "HTTP-Referer": openRouterConfig.siteUrl,
                    "X-Title": openRouterConfig.siteName
                }
            });

            if (completion.choices?.[0]?.message?.content) {
                const title = completion.choices[0].message.content.trim();
                console.log('âœ… æ ‡é¢˜ç”ŸæˆæˆåŠŸ');
                return title;
            }

            throw new Error('æ ‡é¢˜ç”Ÿæˆå¤±è´¥ï¼šAPIå“åº”æ ¼å¼é”™è¯¯æˆ–å†…å®¹ä¸ºç©º');
        } catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            console.error('ğŸš¨ æ ‡é¢˜ç”Ÿæˆå¤±è´¥:', errorMessage);
            throw error;
        }
    }
}
